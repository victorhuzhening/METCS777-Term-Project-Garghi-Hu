{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T16:07:23.649913Z",
     "start_time": "2025-12-05T16:07:19.319770Z"
    }
   },
   "source": [
    "from data import *\n",
    "from pretrained_models import *\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from mediapipe.tasks.python.vision.hand_landmarker import HandLandmarkerResult\n",
    "from tokenizer import *\n",
    "# from train import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sanity Check",
   "id": "aceed76a2b009de9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:46:51.336046Z",
     "start_time": "2025-12-05T03:46:51.314458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MediaPipeCFG = MediaPipeCfg(\"pretrained_model/hand_landmarker.task\")\n",
    "# options = MediaPipeCFG.create_options()\n",
    "# MP_model = MediaPipeCFG.HandLandmarker.create_from_options(options)"
   ],
   "id": "d6358d07f8fb7b45",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:46:51.486361Z",
     "start_time": "2025-12-05T03:46:51.474752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MMPoseCFG = MMPoseCfg(checkpoint_path='pretrained_model/checkpoint/rtmpose-s_simcc-body7_pt-body7_420e-256x192-acd4a1ef_20230504.pth',\n",
    "#                       config_path='pretrained_model/mmpose_config/rtmpose_m_8xb256-420e_coco-256x192.py')\n",
    "# body_model = MMPoseCFG.create_model()"
   ],
   "id": "2a4048478593bab3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:46:51.734894Z",
     "start_time": "2025-12-05T03:46:51.718959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pre_train_dataset = ASLData(\n",
    "#     video_dir=\"data/raw_videos\",\n",
    "#     MP_model=MP_model,\n",
    "#     body_cfg=MMPoseCFG,\n",
    "#     body_model=body_model,\n",
    "#     labels_path=\"data/how2sign_realigned_train.csv\",\n",
    "#     min_frequency=1,\n",
    "#     max_frames=300,\n",
    "#     frame_subsample=2,\n",
    "# )\n",
    "#\n",
    "# pre_train_loader = DataLoader(\n",
    "#     pre_train_dataset,\n",
    "#     batch_size=8,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0,\n",
    "#     collate_fn=lambda b: asl_collate_func(b, pad_id=pre_train_dataset.pad_id),\n",
    "# )"
   ],
   "id": "17db5e3ecba609bd",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:46:52.568022Z",
     "start_time": "2025-12-05T03:46:52.552402Z"
    }
   },
   "cell_type": "code",
   "source": "# OneSample = next(iter(pre_train_loader))",
   "id": "29fbf0c787ba7902",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Write converted JSON to local dir for training",
   "id": "99e231e4bc1e3690"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T06:40:23.697161Z",
     "start_time": "2025-12-05T06:40:23.650995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MediaPipeCFG = MediaPipeCfg(\"pretrained_model/hand_landmarker.task\")\n",
    "options = MediaPipeCFG.create_options()\n",
    "MP_model = MediaPipeCFG.HandLandmarker.create_from_options(options)"
   ],
   "id": "5bce19e916d2f068",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T06:40:24.265411Z",
     "start_time": "2025-12-05T06:40:23.716434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MMPoseCFG = MMPoseCfg(checkpoint_path='pretrained_model/checkpoint/rtmpose-s_simcc-body7_pt-body7_420e-256x192-acd4a1ef_20230504.pth',\n",
    "                      config_path='pretrained_model/mmpose_config/rtmpose_m_8xb256-420e_coco-256x192.py')\n",
    "body_model = MMPoseCFG.create_model()"
   ],
   "id": "209e0bd04a255d41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: pretrained_model/checkpoint/rtmpose-s_simcc-body7_pt-body7_420e-256x192-acd4a1ef_20230504.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for backbone.stem.0.conv.weight: copying a param with shape torch.Size([16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 3, 3, 3]).\n",
      "size mismatch for backbone.stem.0.bn.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "size mismatch for backbone.stem.0.bn.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "size mismatch for backbone.stem.0.bn.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "size mismatch for backbone.stem.0.bn.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "size mismatch for backbone.stem.1.conv.weight: copying a param with shape torch.Size([16, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 24, 3, 3]).\n",
      "size mismatch for backbone.stem.1.bn.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "size mismatch for backbone.stem.1.bn.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "size mismatch for backbone.stem.1.bn.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "size mismatch for backbone.stem.1.bn.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "size mismatch for backbone.stem.2.conv.weight: copying a param with shape torch.Size([32, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([48, 24, 3, 3]).\n",
      "size mismatch for backbone.stem.2.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stem.2.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stem.2.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stem.2.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.0.conv.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 48, 3, 3]).\n",
      "size mismatch for backbone.stage1.0.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage1.0.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage1.0.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage1.0.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage1.1.main_conv.conv.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 96, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.main_conv.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.short_conv.conv.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 96, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.short_conv.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.final_conv.conv.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 96, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage1.1.final_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([48, 48, 3, 3]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([32, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([48, 1, 5, 5]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([32, 32, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 48, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for backbone.stage1.1.attention.fc.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 96, 1, 1]).\n",
      "size mismatch for backbone.stage1.1.attention.fc.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.0.conv.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 96, 3, 3]).\n",
      "size mismatch for backbone.stage2.0.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage2.0.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage2.0.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage2.0.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage2.1.main_conv.conv.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 192, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.main_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.short_conv.conv.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 192, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.short_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.final_conv.conv.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 192, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage2.1.final_conv.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 96, 3, 3]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([64, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([96, 1, 5, 5]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 96, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv1.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 96, 3, 3]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv1.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv1.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv1.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv1.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([64, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([96, 1, 5, 5]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 96, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([96]).\n",
      "size mismatch for backbone.stage2.1.attention.fc.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 192, 1, 1]).\n",
      "size mismatch for backbone.stage2.1.attention.fc.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.0.conv.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 192, 3, 3]).\n",
      "size mismatch for backbone.stage3.0.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage3.0.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage3.0.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage3.0.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage3.1.main_conv.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 384, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.main_conv.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.short_conv.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 384, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.short_conv.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.final_conv.conv.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 384, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage3.1.final_conv.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 192, 3, 3]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([128, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([192, 1, 5, 5]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 192, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 192, 3, 3]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv1.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv1.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv1.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv1.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([128, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([192, 1, 5, 5]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 192, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stage3.1.attention.fc.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 384, 1, 1]).\n",
      "size mismatch for backbone.stage3.1.attention.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.0.conv.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([768, 384, 3, 3]).\n",
      "size mismatch for backbone.stage4.0.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.0.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.0.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.0.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.1.conv1.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 768, 1, 1]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.1.conv1.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.1.conv2.conv.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 1536, 1, 1]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.1.conv2.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.2.main_conv.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 768, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.main_conv.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.short_conv.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 768, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.short_conv.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.final_conv.conv.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 768, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.2.final_conv.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 384, 3, 3]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.conv.weight: copying a param with shape torch.Size([256, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([384, 1, 5, 5]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.conv.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 384, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stage4.2.attention.fc.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 768, 1, 1]).\n",
      "size mismatch for backbone.stage4.2.attention.fc.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for head.final_layer.weight: copying a param with shape torch.Size([17, 512, 7, 7]) from checkpoint, the shape in current model is torch.Size([17, 768, 7, 7]).\n",
      "missing keys in source state_dict: backbone.stage1.1.blocks.1.conv1.conv.weight, backbone.stage1.1.blocks.1.conv1.bn.weight, backbone.stage1.1.blocks.1.conv1.bn.bias, backbone.stage1.1.blocks.1.conv1.bn.running_mean, backbone.stage1.1.blocks.1.conv1.bn.running_var, backbone.stage1.1.blocks.1.conv2.depthwise_conv.conv.weight, backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight, backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias, backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.running_mean, backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.running_var, backbone.stage1.1.blocks.1.conv2.pointwise_conv.conv.weight, backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight, backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias, backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.running_mean, backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.running_var, backbone.stage2.1.blocks.2.conv1.conv.weight, backbone.stage2.1.blocks.2.conv1.bn.weight, backbone.stage2.1.blocks.2.conv1.bn.bias, backbone.stage2.1.blocks.2.conv1.bn.running_mean, backbone.stage2.1.blocks.2.conv1.bn.running_var, backbone.stage2.1.blocks.2.conv2.depthwise_conv.conv.weight, backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight, backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias, backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.running_mean, backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.running_var, backbone.stage2.1.blocks.2.conv2.pointwise_conv.conv.weight, backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight, backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias, backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.running_mean, backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.running_var, backbone.stage2.1.blocks.3.conv1.conv.weight, backbone.stage2.1.blocks.3.conv1.bn.weight, backbone.stage2.1.blocks.3.conv1.bn.bias, backbone.stage2.1.blocks.3.conv1.bn.running_mean, backbone.stage2.1.blocks.3.conv1.bn.running_var, backbone.stage2.1.blocks.3.conv2.depthwise_conv.conv.weight, backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight, backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias, backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.running_mean, backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.running_var, backbone.stage2.1.blocks.3.conv2.pointwise_conv.conv.weight, backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight, backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias, backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.running_mean, backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.running_var, backbone.stage3.1.blocks.2.conv1.conv.weight, backbone.stage3.1.blocks.2.conv1.bn.weight, backbone.stage3.1.blocks.2.conv1.bn.bias, backbone.stage3.1.blocks.2.conv1.bn.running_mean, backbone.stage3.1.blocks.2.conv1.bn.running_var, backbone.stage3.1.blocks.2.conv2.depthwise_conv.conv.weight, backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight, backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias, backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.running_mean, backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.running_var, backbone.stage3.1.blocks.2.conv2.pointwise_conv.conv.weight, backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight, backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias, backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.running_mean, backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.running_var, backbone.stage3.1.blocks.3.conv1.conv.weight, backbone.stage3.1.blocks.3.conv1.bn.weight, backbone.stage3.1.blocks.3.conv1.bn.bias, backbone.stage3.1.blocks.3.conv1.bn.running_mean, backbone.stage3.1.blocks.3.conv1.bn.running_var, backbone.stage3.1.blocks.3.conv2.depthwise_conv.conv.weight, backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight, backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias, backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.running_mean, backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.running_var, backbone.stage3.1.blocks.3.conv2.pointwise_conv.conv.weight, backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight, backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias, backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.running_mean, backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.running_var, backbone.stage4.2.blocks.1.conv1.conv.weight, backbone.stage4.2.blocks.1.conv1.bn.weight, backbone.stage4.2.blocks.1.conv1.bn.bias, backbone.stage4.2.blocks.1.conv1.bn.running_mean, backbone.stage4.2.blocks.1.conv1.bn.running_var, backbone.stage4.2.blocks.1.conv2.depthwise_conv.conv.weight, backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight, backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias, backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.running_mean, backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.running_var, backbone.stage4.2.blocks.1.conv2.pointwise_conv.conv.weight, backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight, backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias, backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.running_mean, backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.running_var\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T06:40:24.665900Z",
     "start_time": "2025-12-05T06:40:24.351899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pre_train_dataset = ASLData(\n",
    "#     video_dir=\"data/raw_videos\",\n",
    "#     MP_model=MP_model,\n",
    "#     body_cfg=MMPoseCFG,\n",
    "#     body_model=body_model,\n",
    "#     labels_path=\"data/how2sign_realigned_train.csv\",\n",
    "#     min_frequency=1,\n",
    "#     max_frames=300,\n",
    "#     frame_subsample=2,\n",
    "# )\n",
    "#\n",
    "# pre_train_loader = DataLoader(\n",
    "#     pre_train_dataset,\n",
    "#     batch_size=8,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0,\n",
    "#     collate_fn=lambda b: asl_collate_func(b, pad_id=pre_train_dataset.pad_id),\n",
    "# )"
   ],
   "id": "c262dc564f03e86d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T06:40:24.700074Z",
     "start_time": "2025-12-05T06:40:24.684104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save_dir = \"pre_train_data\"\n",
    "# os.makedirs(save_dir, exist_ok=True)"
   ],
   "id": "8826148f83d87ef2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-12-05T16:02:44.139798800Z",
     "start_time": "2025-12-05T06:41:35.437051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "#\n",
    "# pre_train_dataset = ASLData(\n",
    "#     video_dir=\"data/raw_videos\",\n",
    "#     MP_model=MP_model,\n",
    "#     body_cfg=MMPoseCFG,\n",
    "#     body_model=body_model,\n",
    "#     labels_path=\"data/how2sign_realigned_train.csv\",\n",
    "#     min_frequency=1,\n",
    "#     max_frames=300,\n",
    "#     frame_subsample=2,\n",
    "# )\n",
    "#\n",
    "# pre_train_loader = DataLoader(\n",
    "#     pre_train_dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     num_workers=0,\n",
    "#     collate_fn=lambda b: b[0],\n",
    "# )\n",
    "#\n",
    "# # Save vocab meta info once\n",
    "# torch.save(\n",
    "#     {\n",
    "#         \"vocab\": pre_train_dataset.vocab,\n",
    "#         \"pad_id\": pre_train_dataset.pad_id,\n",
    "#     },\n",
    "#     os.path.join(save_dir, \"vocab_meta.pt\"),\n",
    "# )\n",
    "#\n",
    "# for idx, sample in enumerate(pre_train_loader):\n",
    "#     # sample is the dict from __getitem__:\n",
    "#     # {\n",
    "#     #   \"pose\": [T', D],\n",
    "#     #   \"pose_len\": int,\n",
    "#     #   \"label_ids\": [L],\n",
    "#     #   \"label_len\": int,\n",
    "#     #   \"filename\": str,\n",
    "#     #   \"raw_label\": str,\n",
    "#     # }\n",
    "#\n",
    "#     # we move tensors to CPU just to be safe\n",
    "#     sample_to_save = {\n",
    "#         \"features\": sample[\"features\"].cpu(),\n",
    "#         \"feature_len\": int(sample[\"feature_len\"]),\n",
    "#         \"label_ids\": sample[\"label_ids\"].cpu(),\n",
    "#         \"label_len\": int(sample[\"label_len\"]),\n",
    "#         \"filename\": sample[\"filename\"],\n",
    "#         \"raw_label\": sample[\"raw_label\"],\n",
    "#     }\n",
    "#\n",
    "#     out_path = os.path.join(save_dir, f\"sample_{idx:05d}.pt\")\n",
    "#     torch.save(sample_to_save, out_path)\n",
    "#\n",
    "#     if (idx + 1) % 50 == 0:\n",
    "#         print(f\"PROGRESS === Saved {idx+1} samples...\")\n"
   ],
   "id": "a9f3796bddc43f72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS === Saved 50 samples...\n",
      "PROGRESS === Saved 100 samples...\n",
      "PROGRESS === Saved 150 samples...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Testing model",
   "id": "123f8343f7b38bcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:07:48.988261Z",
     "start_time": "2025-12-05T16:07:48.958486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from glob import glob\n",
    "\n",
    "class PrecomputedHow2Sign(Dataset):\n",
    "    def __init__(self, feature_dir: str):\n",
    "        self.feature_paths = sorted(glob(os.path.join(feature_dir, \"sample_*.pt\")))\n",
    "        if not self.feature_paths:\n",
    "            raise RuntimeError(f\"No precomputed samples found in {feature_dir}\")\n",
    "\n",
    "        meta = torch.load(os.path.join(feature_dir, \"vocab_meta.pt\"))\n",
    "        self.vocab = meta[\"vocab\"]\n",
    "        self.pad_id = meta[\"pad_id\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.load(self.feature_paths[idx])\n",
    "        return sample\n",
    "\n",
    "pre_ds = PrecomputedHow2Sign(\"data/pre_train_data\")\n",
    "\n",
    "vocab = pre_ds.vocab\n",
    "pad_id = pre_ds.pad_id\n",
    "id_to_token = {idx: tok for tok, idx in vocab.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "loader = DataLoader(\n",
    "    pre_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda b: asl_collate_func(b, pad_id=pad_id),\n",
    ")\n",
    "\n",
    "first_batch = next(iter(loader))\n",
    "feature_dim = first_batch[\"features\"].shape[-1]\n",
    "#\n",
    "# model = PoseToTextModel(\n",
    "#     pose_dim=pose_dim,\n",
    "#     enc_hidden=256,\n",
    "#     vocab_size=vocab_size,\n",
    "#     emb_dim=256,\n",
    "#     pad_id=pad_id,\n",
    "# ).to(device)"
   ],
   "id": "bc7c19f9588caf57",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:07:53.647231Z",
     "start_time": "2025-12-05T16:07:53.633132Z"
    }
   },
   "cell_type": "code",
   "source": "feature_dim",
   "id": "92a405870e757b03",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T21:36:06.433702Z",
     "start_time": "2025-12-02T21:36:06.417463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class PoseToTextModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pose_dim: int,          # D: feature dimension of pose per frame\n",
    "        enc_hidden: int,        # encoder GRU hidden size per direction\n",
    "        vocab_size: int,        # |V|\n",
    "        emb_dim: int,           # token embedding dim\n",
    "        pad_id: int,\n",
    "        num_enc_layers: int = 1,\n",
    "        num_dec_layers: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pad_id = pad_id\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # Encoder: Bi-GRU over pose sequence\n",
    "        self.encoder = nn.GRU(\n",
    "            input_size=pose_dim,\n",
    "            hidden_size=enc_hidden,\n",
    "            num_layers=num_enc_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        # Decoder embedding\n",
    "        self.emb = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=emb_dim,\n",
    "            padding_idx=pad_id,\n",
    "        )\n",
    "\n",
    "        # Decoder GRU: hidden size = 2 * enc_hidden (concat directions)\n",
    "        self.decoder = nn.GRU(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=2 * enc_hidden,\n",
    "            num_layers=num_dec_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # Final projection to vocab\n",
    "        self.out = nn.Linear(2 * enc_hidden, vocab_size)\n",
    "\n",
    "    def encode(self, pose, pose_len):\n",
    "        \"\"\"\n",
    "        pose: [B, T, D]\n",
    "        pose_len: [B]\n",
    "        Returns: encoder final hidden state [num_layers*2, B, H]\n",
    "        \"\"\"\n",
    "        # Pack for efficient RNN\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            pose,\n",
    "            lengths=pose_len.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False,\n",
    "        )\n",
    "        enc_out, h_n = self.encoder(packed)\n",
    "        # h_n: [num_layers*2, B, enc_hidden]\n",
    "        return h_n\n",
    "\n",
    "    def forward(self, pose, pose_len, labels):\n",
    "        \"\"\"\n",
    "        pose:   [B, T, D]\n",
    "        pose_len: [B]\n",
    "        labels: [B, L]  (with <bos> ... <eos> and <pad>)\n",
    "\n",
    "        We use teacher forcing:\n",
    "          decoder inputs: labels[:, :-1]\n",
    "          targets:        labels[:, 1:]\n",
    "        Returns:\n",
    "          logits: [B, L-1, vocab_size]\n",
    "        \"\"\"\n",
    "        B, T, D = pose.shape\n",
    "        B2, L = labels.shape\n",
    "        assert B == B2\n",
    "\n",
    "        # ---- Encode ----\n",
    "        h_n = self.encode(pose, pose_len)  # [num_layers*2, B, enc_hidden]\n",
    "\n",
    "        # Merge directions for final layer into a single initial hidden state\n",
    "        # For simplicity, we only use last layers forward/backward\n",
    "        # h_n_last: [2, B, enc_hidden] -> concat -> [1, B, 2*enc_hidden]\n",
    "        num_layers_times_dir, B_enc, H = h_n.shape\n",
    "        assert B_enc == B\n",
    "        h_n_last = h_n[-2:]                 # [2, B, H] (last layer forward/backward)\n",
    "        h0_dec = torch.cat(\n",
    "            [h_n_last[0], h_n_last[1]], dim=-1\n",
    "        ).unsqueeze(0)                      # [1, B, 2H]\n",
    "\n",
    "        # ---- Decode with teacher forcing ----\n",
    "        # decoder input is labels shifted right (all but last token)\n",
    "        dec_inp = labels[:, :-1]            # [B, L-1]\n",
    "        emb = self.emb(dec_inp)             # [B, L-1, emb_dim]\n",
    "\n",
    "        dec_out, _ = self.decoder(emb, h0_dec)  # [B, L-1, 2H]\n",
    "        logits = self.out(dec_out)              # [B, L-1, vocab_size]\n",
    "\n",
    "        return logits\n"
   ],
   "id": "6f9161bc051737c0",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T21:39:22.022451Z",
     "start_time": "2025-12-02T21:39:22.013348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def build_id_to_token(vocab: dict) -> dict:\n",
    "    \"\"\"vocab: {token: id} -> {id: token}\"\"\"\n",
    "    return {idx: tok for tok, idx in vocab.items()}\n",
    "\n",
    "\n",
    "def tokens_to_text(\n",
    "    ids,\n",
    "    id_to_token,\n",
    "    pad_id: int,\n",
    "    bos_token: str = \"<bos>\",\n",
    "    eos_token: str = \"<eos>\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a sequence of token IDs into a space-separated string.\n",
    "    Ignores <pad>, optionally removes <bos>, and stops at <eos>.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for i in ids:\n",
    "        if int(i) == pad_id:\n",
    "            continue\n",
    "        tok = id_to_token.get(int(i), \"<unk>\")\n",
    "        if tok == bos_token:\n",
    "            continue\n",
    "        if tok == eos_token:\n",
    "            break\n",
    "        tokens.append(tok)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "def bleu1(pred_tokens, ref_tokens):\n",
    "    \"\"\"\n",
    "    Simple BLEU-1 (unigram BLEU) with brevity penalty.\n",
    "    pred_tokens, ref_tokens: lists of tokens (strings).\n",
    "    \"\"\"\n",
    "    if len(pred_tokens) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    pred_counts = Counter(pred_tokens)\n",
    "    ref_counts = Counter(ref_tokens)\n",
    "    overlap = sum(min(pred_counts[w], ref_counts[w]) for w in pred_counts)\n",
    "\n",
    "    precision = overlap / len(pred_tokens)\n",
    "\n",
    "    # brevity penalty\n",
    "    ref_len = len(ref_tokens)\n",
    "    pred_len = len(pred_tokens)\n",
    "    if pred_len == 0:\n",
    "        return 0.0\n",
    "    if pred_len > ref_len:\n",
    "        bp = 1.0\n",
    "    else:\n",
    "        bp = math.exp(1.0 - ref_len / pred_len)\n",
    "\n",
    "    return bp * precision\n",
    "\n",
    "\n",
    "def rouge1_f1(pred_tokens, ref_tokens):\n",
    "    \"\"\"\n",
    "    Very simple ROUGE-1 F1 (over unigrams).\n",
    "    \"\"\"\n",
    "    if not pred_tokens or not ref_tokens:\n",
    "        return 0.0\n",
    "\n",
    "    pred_counts = Counter(pred_tokens)\n",
    "    ref_counts = Counter(ref_tokens)\n",
    "\n",
    "    overlap = sum(min(pred_counts[w], ref_counts[w]) for w in pred_counts)\n",
    "\n",
    "    precision = overlap / len(pred_tokens)\n",
    "    recall = overlap / len(ref_tokens)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return 2 * precision * recall / (precision + recall)\n"
   ],
   "id": "426a8bbaf6dac421",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T21:41:40.942589Z",
     "start_time": "2025-12-02T21:39:45.956663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    total_bleu = 0.0\n",
    "    total_rouge = 0.0\n",
    "    total_sentences = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        pose = batch[\"pose\"].to(device)          # [B, T, D]\n",
    "        pose_len = batch[\"pose_len\"].to(device)  # [B]\n",
    "        labels = batch[\"labels\"].to(device)      # [B, L]\n",
    "\n",
    "        # ----- forward -----\n",
    "        logits = model(pose, pose_len, labels)   # [B, L-1, V]\n",
    "\n",
    "        # Targets are labels shifted left\n",
    "        target = labels[:, 1:]                   # [B, L-1]\n",
    "\n",
    "        B, Lm1, V = logits.shape\n",
    "        loss = loss_fn(\n",
    "            logits.reshape(B * Lm1, V),\n",
    "            target.reshape(B * Lm1),\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ----- accumulate loss (per non-pad token) -----\n",
    "        with torch.no_grad():\n",
    "            non_pad = (target != my_pad_id).sum().item()\n",
    "            non_pad = max(non_pad, 1)\n",
    "            total_loss += loss.item() * non_pad\n",
    "            total_tokens += non_pad\n",
    "\n",
    "            # ----- compute BLEU / ROUGE for this batch -----\n",
    "            # Greedy predictions: argmax over vocab\n",
    "            pred_ids_batch = logits.argmax(dim=-1)   # [B, L-1]\n",
    "            ref_ids_batch = target                   # [B, L-1]\n",
    "\n",
    "            for b in range(B):\n",
    "                pred_ids = pred_ids_batch[b].tolist()\n",
    "                ref_ids = ref_ids_batch[b].tolist()\n",
    "\n",
    "                # Convert id sequences to token sequences (strings)\n",
    "                pred_str = tokens_to_text(\n",
    "                    pred_ids,\n",
    "                    id_to_token,\n",
    "                    pad_id=my_pad_id,\n",
    "                    bos_token=\"<bos>\",\n",
    "                    eos_token=\"<eos>\",\n",
    "                )\n",
    "                ref_str = tokens_to_text(\n",
    "                    ref_ids,\n",
    "                    id_to_token,\n",
    "                    pad_id=my_pad_id,\n",
    "                    bos_token=\"<bos>\",\n",
    "                    eos_token=\"<eos>\",\n",
    "                )\n",
    "\n",
    "                pred_toks = pred_str.split()\n",
    "                ref_toks = ref_str.split()\n",
    "\n",
    "                if len(ref_toks) == 0:\n",
    "                    continue  # skip entirely empty reference\n",
    "\n",
    "                b_bleu = bleu1(pred_toks, ref_toks)\n",
    "                b_rouge = rouge1_f1(pred_toks, ref_toks)\n",
    "\n",
    "                total_bleu += b_bleu\n",
    "                total_rouge += b_rouge\n",
    "                total_sentences += 1\n",
    "\n",
    "    avg_loss = total_loss / max(total_tokens, 1)\n",
    "    avg_bleu = total_bleu / max(total_sentences, 1)\n",
    "    avg_rouge = total_rouge / max(total_sentences, 1)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch} | \"\n",
    "        f\"avg token loss: {avg_loss:.4f} | \"\n",
    "        f\"BLEU-1: {avg_bleu:.4f} | ROUGE-1 F1: {avg_rouge:.4f}\"\n",
    "    )\n"
   ],
   "id": "b67b2c8ccab75e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | avg token loss: 5.3558 | BLEU-1: 0.0561 | ROUGE-1 F1: 0.0740\n",
      "Epoch 2 | avg token loss: 4.7113 | BLEU-1: 0.1413 | ROUGE-1 F1: 0.2191\n",
      "Epoch 3 | avg token loss: 4.1272 | BLEU-1: 0.1299 | ROUGE-1 F1: 0.1901\n",
      "Epoch 4 | avg token loss: 3.6539 | BLEU-1: 0.2273 | ROUGE-1 F1: 0.2987\n",
      "Epoch 5 | avg token loss: 3.2051 | BLEU-1: 0.3029 | ROUGE-1 F1: 0.3381\n",
      "Epoch 6 | avg token loss: 2.8048 | BLEU-1: 0.3726 | ROUGE-1 F1: 0.3973\n",
      "Epoch 7 | avg token loss: 2.4183 | BLEU-1: 0.4627 | ROUGE-1 F1: 0.4767\n",
      "Epoch 8 | avg token loss: 2.0040 | BLEU-1: 0.5471 | ROUGE-1 F1: 0.5625\n",
      "Epoch 9 | avg token loss: 1.6619 | BLEU-1: 0.6141 | ROUGE-1 F1: 0.6295\n",
      "Epoch 10 | avg token loss: 1.3469 | BLEU-1: 0.7407 | ROUGE-1 F1: 0.7407\n",
      "Epoch 11 | avg token loss: 1.0729 | BLEU-1: 0.7973 | ROUGE-1 F1: 0.7973\n",
      "Epoch 12 | avg token loss: 0.8664 | BLEU-1: 0.8447 | ROUGE-1 F1: 0.8447\n",
      "Epoch 13 | avg token loss: 0.6858 | BLEU-1: 0.8784 | ROUGE-1 F1: 0.8784\n",
      "Epoch 14 | avg token loss: 0.5726 | BLEU-1: 0.8807 | ROUGE-1 F1: 0.8807\n",
      "Epoch 15 | avg token loss: 0.4827 | BLEU-1: 0.8883 | ROUGE-1 F1: 0.8883\n",
      "Epoch 16 | avg token loss: 0.4110 | BLEU-1: 0.8939 | ROUGE-1 F1: 0.8939\n",
      "Epoch 17 | avg token loss: 0.3609 | BLEU-1: 0.8992 | ROUGE-1 F1: 0.8992\n",
      "Epoch 18 | avg token loss: 0.3233 | BLEU-1: 0.9056 | ROUGE-1 F1: 0.9056\n",
      "Epoch 19 | avg token loss: 0.2922 | BLEU-1: 0.9078 | ROUGE-1 F1: 0.9078\n",
      "Epoch 20 | avg token loss: 0.2677 | BLEU-1: 0.9149 | ROUGE-1 F1: 0.9149\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6a8d3a817ebe30ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
